{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/crop_yield.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1000000, Columns: 10, Columns: Index(['Region', 'Soil_Type', 'Crop', 'Rainfall_mm', 'Temperature_Celsius',\n",
      "       'Fertilizer_Used', 'Irrigation_Used', 'Weather_Condition',\n",
      "       'Days_to_Harvest', 'Yield_tons_per_hectare'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_columns = data.shape\n",
    "print(f\"Rows: {num_rows}, Columns: {num_columns}, Columns: {data.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region                    0\n",
      "Soil_Type                 0\n",
      "Crop                      0\n",
      "Rainfall_mm               0\n",
      "Temperature_Celsius       0\n",
      "Fertilizer_Used           0\n",
      "Irrigation_Used           0\n",
      "Weather_Condition         0\n",
      "Days_to_Harvest           0\n",
      "Yield_tons_per_hectare    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: ['West' 'South' 'North' 'East']\n",
      "\n",
      "Soil_Type: ['Sandy' 'Clay' 'Loam' 'Silt' 'Peaty' 'Chalky']\n",
      "\n",
      "Crop: ['Cotton' 'Rice' 'Barley' 'Soybean' 'Wheat' 'Maize']\n",
      "\n",
      "Weather_Condition: ['Cloudy' 'Rainy' 'Sunny']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in ['Region', 'Soil_Type', 'Crop', 'Weather_Condition']:\n",
    "    print(f\"{col}: {data[col].unique()}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean Columns: Index(['Fertilizer_Used', 'Irrigation_Used'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check for boolean columns\n",
    "bool_columns = data.select_dtypes(include=['bool']).columns\n",
    "print(\"Boolean Columns:\", bool_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean columns to integers\n",
    "data[\"Fertilizer_Used\"] = data[\"Fertilizer_Used\"].astype(int)\n",
    "data[\"Irrigation_Used\"] = data[\"Irrigation_Used\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Label encoders saved as 'label_encoders.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Apply label encoding to categorical columns\n",
    "categorical_cols = [\"Region\", \"Soil_Type\", \"Crop\", \"Weather_Condition\"]\n",
    "label_encoders = {}\n",
    "\n",
    "\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le  # Store encoders for future reference\n",
    "    \n",
    "    \n",
    "    \n",
    "joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
    "print(\"âœ… Label encoders saved as 'label_encoders.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Region  Soil_Type  Crop  Rainfall_mm  Temperature_Celsius  Fertilizer_Used  \\\n",
      "0       3          4     1   897.077239            27.676966                0   \n",
      "1       2          1     3   992.673282            18.026142                1   \n",
      "2       1          2     0   147.998025            29.794042                0   \n",
      "3       1          4     4   986.866331            16.644190                0   \n",
      "4       2          5     5   730.379174            31.620687                1   \n",
      "\n",
      "   Irrigation_Used  Weather_Condition  Days_to_Harvest  Yield_tons_per_hectare  \n",
      "0                1                  0              122                6.555816  \n",
      "1                1                  1              140                8.527341  \n",
      "2                0                  2              106                1.127443  \n",
      "3                1                  1              146                6.517573  \n",
      "4                1                  0              110                7.248251  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data.drop(columns=[\"Yield_tons_per_hectare\"]))  # Excluding target column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Defining features (X) and target variable (y)\n",
    "X = data.drop(columns=[\"Yield_tons_per_hectare\"])\n",
    "y = data[\"Yield_tons_per_hectare\"]\n",
    "\n",
    "\n",
    "\n",
    "# Splitting the dataset (80% Training, 20% Testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used in training: ['Region', 'Soil_Type', 'Crop', 'Rainfall_mm', 'Temperature_Celsius', 'Fertilizer_Used', 'Irrigation_Used', 'Weather_Condition', 'Days_to_Harvest']\n",
      "Number of features: 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Features used in training:\", X.columns.tolist())\n",
    "print(\"Number of features:\", len(X.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ XGBoost Performance\n",
      "MAE: 0.4002273553954539\n",
      "MSE: 0.25158681884202466\n",
      "RÂ² Score: 0.9127327562670771\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define XGBoost model\n",
    "xgb_model = XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"ðŸ“Œ XGBoost Performance\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_xgb)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_xgb)}\")\n",
    "print(f\"RÂ² Score: {r2_score(y_test, y_pred_xgb)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624\n",
      "[LightGBM] [Info] Number of data points in the train set: 800000, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 4.649019\n",
      "ðŸ“Œ LightGBM Performance\n",
      "MAE: 0.4000343164391992\n",
      "MSE: 0.25133715381298605\n",
      "RÂ² Score: 0.9128193569047455\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Define LightGBM model\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"ðŸ“Œ LightGBM Performance\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_lgb)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_lgb)}\")\n",
    "print(f\"RÂ² Score: {r2_score(y_test, y_pred_lgb)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved successfully as lightgbm_crop_yield_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(lgb_model, \"lightgbm_crop_yield_model.pkl\")\n",
    "\n",
    "print(\"âœ… Model saved successfully as lightgbm_crop_yield_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Region Encoding:\n",
      "  0 â†’ 0\n",
      "  1 â†’ 1\n",
      "  2 â†’ 2\n",
      "  3 â†’ 3\n",
      "------------------------------\n",
      "ðŸ”¹ Soil_Type Encoding:\n",
      "  0 â†’ 0\n",
      "  1 â†’ 1\n",
      "  2 â†’ 2\n",
      "  3 â†’ 3\n",
      "  4 â†’ 4\n",
      "  5 â†’ 5\n",
      "------------------------------\n",
      "ðŸ”¹ Crop Encoding:\n",
      "  0 â†’ 0\n",
      "  1 â†’ 1\n",
      "  2 â†’ 2\n",
      "  3 â†’ 3\n",
      "  4 â†’ 4\n",
      "  5 â†’ 5\n",
      "------------------------------\n",
      "ðŸ”¹ Weather_Condition Encoding:\n",
      "  0 â†’ 0\n",
      "  1 â†’ 1\n",
      "  2 â†’ 2\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved label encoders\n",
    "label_encoders = joblib.load(\"label_encoders.pkl\")\n",
    "\n",
    "# Print the mapping of categories to encoded values\n",
    "for col, encoder in label_encoders.items():\n",
    "    print(f\"ðŸ”¹ {col} Encoding:\")\n",
    "    for idx, class_name in enumerate(encoder.classes_):\n",
    "        print(f\"  {class_name} â†’ {idx}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
